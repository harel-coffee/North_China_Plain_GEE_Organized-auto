{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Make_Sample_Classification():\n",
    "    '''This class stack 3 functions together and does not have any self.variables.\n",
    "    \n",
    "    function_1--> Reduce an input FeatureCollection with a given percentage\n",
    "    \n",
    "    function_2--> Create a list of tuples from input FeatureCollection,\n",
    "      Note: the input FeatureCollection must have Landsat/Fourier/Mean-normalized band values\n",
    "      The ruturn is like:\n",
    "      [ ('Landsat',<FeatureCollection with {Landsat} values>)\n",
    "        ('Fourier',<FeatureCollection with {Fourier} values>)\n",
    "        ('Landsat_Fourier',<FeatureCollection with {Landsat and Fourier} values>)\n",
    "        ('Landsat_Mean',<FeatureCollection with {Landsat and Mean_nomalized} values>)\n",
    "        ('Fourier_Mean',<FeatureCollection with {Fourier and Mean_nomalized} values>)\n",
    "        ('Landsat_Fourier_Mean',<FeatureCollection with {Landsat_Fourier_Mean} values>)]\n",
    "                                        \n",
    "    function_3--> Create sample_classificaiton instances (aka, classified sample point) without computation in GEE\n",
    "      Note: need to from Class_2_Classify_Fourier_Img import Classification first to use this funcion\n",
    "      In this function,:\n",
    "      1) the input {verified_pt} will be split into a 7/3 partition, the\n",
    "      2) create a classifier (hidden in the Classificaiton class) from the 7 portion, and\n",
    "      3) use the classsifier to classify the left 3 portion of sample points and ,\n",
    "      4) return the classified sample with multiindex of (year,combo_name,percent,tree)\n",
    "                                    \n",
    "    ___________________________________________Sample of Make_Sample_Classification__________________________________________\n",
    "    # define variables for the Sample_classification clas\n",
    "    year_name     = ['2017_2019','2011_2013', '2008_2010']\n",
    "    percent_value = [0,1,2,3,5,7,10,20,30,50,70,100]\n",
    "    tree_num      = [1] + list(range(10,121,10))\n",
    "\n",
    "    # define the path to point_with_value GEE-Path\n",
    "    path = 'users/Jinzhu_Deakin/North_China_Plain/Sample_with_Landsat_Fourier_Normalized'\n",
    "\n",
    "    # instantiate the combo_instance dictionary\n",
    "    Combo_instance_with_village = {}\n",
    "\n",
    "    # Create sample_classification instances through [year] --> [Percent] --> [band_combination] --> [Tree]\n",
    "    for year in year_name:\n",
    "\n",
    "        # import samples\n",
    "        Verified_sample = ee.FeatureCollection(f'{path}/Verified_point_{year}_extract_Landsat_Fourier_Normalized_img')\\\n",
    "                            .filterMetadata('Built', 'equals', 0)\n",
    "        Village_sample  = ee.FeatureCollection(f'{path}/Village_point_{year}_extract_Landsat_Fourier_Normalized_img')\n",
    "\n",
    "        # make sure they are the same size.\n",
    "        min_size = min(Verified_sample.size().getInfo(),Village_sample.size().getInfo())\n",
    "        Verified_sample = Verified_sample.randomColumn('z', 101).limit(min_size,'z')\n",
    "        Village_sample  = Village_sample.randomColumn('z', 101).limit(min_size,'z')\n",
    "\n",
    "        for pct in percent_reduction:\n",
    "\n",
    "            # Create percentage_reduced samples, only use non-built points from verified points\n",
    "            Subset_verified_sample  = Make_Sample_Classification.Step_1_Subset_sample(Verified_sample,pct)\n",
    "            Subset_village_sample   = Make_Sample_Classification.Step_1_Subset_sample(Village_sample,pct)\n",
    "\n",
    "            # Merge Verified_points with Zone_points\n",
    "            Sample_merge = Subset_verified_sample.merge(Subset_village_sample)\n",
    "\n",
    "            # Get the band_combo names\n",
    "            Band_combo   = Make_Sample_Classification.Step_2_Create_Band_Combo(Sample_merge)\n",
    "\n",
    "            for combo in Band_combo:\n",
    "                Accuracy_instance = Make_Sample_Classification.\\\n",
    "                                    Step_3_Create_Classification_Instance(year,Sample_merge,\n",
    "                                                                          combo,tree_num,\n",
    "                                                                          pct,classificaiton_func = Classification ) \n",
    "                Combo_instance_with_village.update(Accuracy_instance)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    def Step_1_Subset_sample(In_sample,percent):\n",
    "\n",
    "        Sample_select_num = int(In_sample.size().getInfo() * percent /100)\n",
    "        print(f'Percetage coresponded size is {Sample_select_num}')\n",
    "\n",
    "        # add some randomness so to make the result more reliable\n",
    "        return In_sample.randomColumn('x', 101).limit(Sample_select_num,'x')\n",
    "\n",
    "    def Step_2_Create_Band_Combo(fe):\n",
    "\n",
    "        # use the first element to get all band name\n",
    "        bands = list(fe.first().getInfo()['properties'].keys())\n",
    "\n",
    "        # get the Landsat_band\n",
    "        Landsat_re   = re.compile(r'^B\\d')\n",
    "        Landsat_band = list(filter(Landsat_re.match,bands))\n",
    "\n",
    "        # get the Fourier_band\n",
    "        Fourier_re   = re.compile(r'^EVI|NDBI|NDVI')\n",
    "        Fourier_band = list(filter(Fourier_re.match,bands))\n",
    "\n",
    "        # get the Mean_Normalized band\n",
    "        Mean_re         = re.compile(r'^Mean')\n",
    "        Mean_Normalized = list(filter(Mean_re.match,bands))\n",
    "\n",
    "        # ________________________Create sample classification instaces_____________________________\n",
    "\n",
    "        # create band_combinations\n",
    "        band_combination = [Landsat_band,\n",
    "                            Fourier_band,\n",
    "                            Landsat_band + Fourier_band,\n",
    "                            Landsat_band + Mean_Normalized,\n",
    "                            Fourier_band + Mean_Normalized,\n",
    "                            Landsat_band + Fourier_band + Mean_Normalized]\n",
    "\n",
    "        # create comno_names\n",
    "        global combination_name\n",
    "        combination_name = ['Landsat',\n",
    "                            'Fourier',\n",
    "                            'Landsat_Fourier',\n",
    "                            'Landsat_Mean',\n",
    "                            'Fourier_Mean',\n",
    "                            'Landsat_Fourier_Mean']\n",
    "\n",
    "\n",
    "        return list(zip(combination_name,band_combination))\n",
    "\n",
    "    def Step_3_Create_Classification_Instance(year,verified_pt,combo,tree_list,percent,classificaiton_func):\n",
    "        # Initiate the Combo_dict\n",
    "        Combo_acc_dict = {}\n",
    "\n",
    "        for tree in tree_list:\n",
    "\n",
    "            combo_name = combo[0]\n",
    "            combo_band = combo[1]\n",
    "\n",
    "            # Instatiate the class with a name\n",
    "            Sample_classification = classificaiton_func( year_name    = year,\n",
    "                                                  Input_band     = combo_band,\n",
    "                                                  Verified_point = verified_pt,\n",
    "                                                  Tree_num       = tree)\n",
    "\n",
    "            # Proceed the classification\n",
    "            Sample_classification.Stp_2_Classification_on_Samples()\n",
    "\n",
    "            # add accuracy to the dictionary\n",
    "            Combo_acc_dict.update({(year,combo_name,percent,tree) : Sample_classification.Test_sample_classification})\n",
    "\n",
    "            # print out the process\n",
    "            print(f'Classification of {year}_{combo_name}_pct_{percent:03}_tree_{tree:04} completed!')\n",
    "\n",
    "        # get the accuracy value\n",
    "        return Combo_acc_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
