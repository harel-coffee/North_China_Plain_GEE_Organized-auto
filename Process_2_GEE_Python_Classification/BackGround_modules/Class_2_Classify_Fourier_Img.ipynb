{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification:\n",
    "\n",
    "    \"\"\"\n",
    "    This class will\n",
    "    1) perform classification on a [Input_img] using [Verified_pt]\n",
    "    2) make a randomeforrest classifier based on [Tree_num] parameter\n",
    "    3) split input sample(Verified_sample) [Training_samples] and [Testing_samples] \n",
    "    4) get [Train_classification] and [Test_classification] based on samples.\n",
    "    \n",
    "    WARNING!!\n",
    "    Make sure [Input_band] is the same with band of [Input_image] if intend to use classifier\n",
    "    generated from Verified_samples.\n",
    "    \n",
    "    For {Input}: \n",
    "    1) The [Input_img] is a string, like:\n",
    "       [Input_img = \"users/wang8052664/Cloud_Free_Img/Landsat_cloud_free_2017_2019\"]\n",
    "    2) The [year_name] is a string like '2017_2019'\n",
    "    3) the [Input_band] defines the bands that are used in the classification\n",
    "    4) the [Verified_point] defines the sample points as the ground truthes,\n",
    "    5) the [Input_band] is used to restrain feature points (by feature.Select()),\n",
    "    6) the [classProperty] is default to 'Built', which is the column name for ground truth\n",
    "    7) The default [Tree_num] is 100.\n",
    "\n",
    "    For {Output}: \n",
    "    1) Classified imgs ==>   [classification_img].\n",
    "    2) Classfied samples ==> [Train_sample_classification]\n",
    "                             [Test_sample_classification].\n",
    "                            \n",
    "    \n",
    "    \n",
    "    __________________________________Sample for classfication on IMAGE___________________________________\n",
    "\n",
    "    verified_sample_2017_2019 = ee.FeatureCollection(\"users/wangjinzhulala/North_China_Plain_Python/Sample_Points/Verified_pt_2017_2019\")\n",
    "    zone_pt = ee.FeatureCollection(\"users/Jinzhu_Deakin/North_China_Plain/Zone_sample_point_1987_1989/Zone_Sample\")\n",
    "\n",
    "    input_point = verified_sample_2017_2019.merge(zone_pt)\n",
    "\n",
    "    # get necessary img and verified points\n",
    "    imput_img = ee.Image(\"users/wang8052664/North_China_Plain/Fourier_imgs/Fourier_img_2017_2019_harmonic_3\")\n",
    "\n",
    "    # Instatiate the class with a name.\n",
    "    test2 = Classification(year_name ='2017_2019',\n",
    "                          Input_img  = imput_img,\n",
    "                          Verified_point = input_point)\n",
    "\n",
    "\n",
    "    # perform the classification on Input_img and Samples\n",
    "    test2.Stp_1_Classification_on_img()\n",
    "    test2.Stp_2_Classification_on_Samples()\n",
    "\n",
    "    # Get the classified img\n",
    "    classified_img = test2.classification_img\n",
    "\n",
    "    # Get the classified samples\n",
    "    train_sample_classified        = test2.Train_sample_classification\n",
    "    test_sample_classified         = test2.Test_sample_classification\n",
    "    \n",
    "    __________________________________Sample for classfication on POINTS___________________________________\n",
    "    \n",
    "    verified_sample_img = ee.FeatureCollection(\"users/Jinzhu_Deakin/North_China_Plain/Sample_with_Landsat_Fourier_Normalized/Verified_point_2017_2019_extract_Landsat_Fourier_Normalized_img\")\n",
    "    zone_pt_img = ee.FeatureCollection(\"users/Jinzhu_Deakin/North_China_Plain/Sample_with_Landsat_Fourier_Normalized/Zone_point_2017_2019_extract_Landsat_Fourier_Normalized_img\")\n",
    "\n",
    "    input_point = verified_sample_img.merge(zone_pt_img)\n",
    "\n",
    "    band_classification = ['NDVI_cos_1','NDVI_cos_2','NDVI_cos_3','NDVI_sin_1','NDVI_sin_2','NDVI_sin_3',\n",
    "                           'NDVI_constant','NDVI_t','NDBI_cos_1','NDBI_cos_2','NDBI_cos_3','NDBI_sin_1',\n",
    "                           'NDBI_sin_2','NDBI_sin_3', 'NDBI_constant','NDBI_t','EVI_cos_1','EVI_cos_2',\n",
    "                           'EVI_cos_3','EVI_sin_1','EVI_sin_2','EVI_sin_3','EVI_constant','EVI_t']\n",
    "\n",
    "    # Instatiate the class with a name.\n",
    "    test3 = Classification(year_name ='2017_2019',\n",
    "                           Verified_point = input_point,\n",
    "                           Input_band=band_classification)\n",
    "\n",
    "\n",
    "    # perform the classification on Samples\n",
    "    test3.Stp_2_Classification_on_Samples()\n",
    "\n",
    "    # Get the classified samples\n",
    "    train_sample_classified        = test3.Train_sample_classification\n",
    "    test_sample_classified         = test3.Test_sample_classification\n",
    "    _______________________________________________________________________________________________\n",
    "   \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self,year_name,\n",
    "                      Verified_point,\n",
    "                      Input_img     = None,\n",
    "                      Input_band    = None,\n",
    "                      Tree_num      = 100,\n",
    "                      Zone_sample   = None,\n",
    "                      classProperty = 'Built'):\n",
    "        \n",
    "        self.Tree_num           = Tree_num\n",
    "        self.Input_img          = Input_img\n",
    "        self.year_name          = year_name\n",
    "        self.Input_band         = Input_band\n",
    "        self.classProperty      = classProperty\n",
    "        self.Verified_point_all = ee.FeatureCollection(Verified_point)\n",
    "        \n",
    "        #__________________________Split the point into built and non-built________________________________________\n",
    "        Verified_point_Built     =  self.Verified_point_all.filterMetadata(classProperty,'equals',1)\n",
    "        Verified_point_non_Built =  self.Verified_point_all.filterMetadata(classProperty,'equals',0)\n",
    "\n",
    "        # 70/30 Train/Test split on built/non-built points.\n",
    "        Verified_built_pts_randomcolumn     = Verified_point_Built\\\n",
    "                                              .randomColumn(columnName = 'random',seed = 101) \n",
    "        Verified_non_built_pts_randomcolumn = Verified_point_non_Built\\\n",
    "                                              .randomColumn(columnName = 'random',seed = 101)\n",
    "\n",
    "\n",
    "        Vetified_built_pts_train     = Verified_built_pts_randomcolumn\\\n",
    "                                       .filterMetadata('random',\"greater_than\",0.3)\n",
    "        Vetified_built_pts_test      = Verified_built_pts_randomcolumn\\\n",
    "                                       .filterMetadata('random',\"not_greater_than\",0.3) \n",
    "\n",
    "        Vetified_non_built_pts_train = Verified_non_built_pts_randomcolumn\\\n",
    "                                      .filterMetadata('random','greater_than',0.3)\n",
    "        Vetified_non_built_pts_test  = Verified_non_built_pts_randomcolumn\\\n",
    "                                      .filterMetadata('random','not_greater_than',0.3) \n",
    "\n",
    "        # Merge train/test datasets respectively.\n",
    "        if Zone_sample != None:\n",
    "            self.Verified_pts_train = Vetified_built_pts_train.merge(Vetified_non_built_pts_train)\\\n",
    "                                                              .merge(Zone_sample)\n",
    "        else:  \n",
    "            self.Verified_pts_train = Vetified_built_pts_train.merge(Vetified_non_built_pts_train)\n",
    "\n",
    "        \n",
    "        self.Verified_pts_test  = Vetified_built_pts_test.merge(Vetified_non_built_pts_test)\n",
    "        \n",
    "        # ________________________________Train the classifier_______________________________________\n",
    "        \n",
    "        # if input img provided, extract its value to Verified points, and make the classifier accordingly \n",
    "        if Input_img == None:\n",
    "            \n",
    "            self.Verified_pts_train_with_img_value = self.Verified_pts_train.select(self.Input_band + [self.classProperty])\n",
    "            self.Verified_pts_test_with_img_value  = self.Verified_pts_test.select(self.Input_band + [self.classProperty])\n",
    "            \n",
    "            self.classifier = ee.Classifier.smileRandomForest(numberOfTrees = self.Tree_num)\\\n",
    "                                       .train(features        = self.Verified_pts_train_with_img_value,\n",
    "                                              inputProperties = self.Input_band,\n",
    "                                              classProperty   = self.classProperty)\n",
    "        elif Input_band == None:\n",
    "            \n",
    "            self.Verified_pts_train_with_img_value = self.Input_img.sampleRegions(collection = self.Verified_pts_train, \n",
    "                                                                                  properties = [self.classProperty], \n",
    "                                                                                  scale      = 30,\n",
    "                                                                                  geometries = False)\n",
    "\n",
    "            self.Verified_pts_test_with_img_value = self.Input_img.sampleRegions(collection  = self.Verified_pts_test, \n",
    "                                                                                  properties = [self.classProperty], \n",
    "                                                                                  scale      = 30,\n",
    "                                                                                  geometries = False)\n",
    "            \n",
    "            self.classifier = ee.Classifier.smileRandomForest(numberOfTrees = self.Tree_num)\\\n",
    "                                       .train(features        = self.Verified_pts_train_with_img_value,\n",
    "                                              inputProperties = self.Input_img.bandNames().getInfo(),\n",
    "                                              classProperty   = self.classProperty)\n",
    "        else:\n",
    "            self.Verified_pts_train_with_img_value = self.Verified_pts_train.select(self.Input_band + [self.classProperty])\n",
    "            self.Verified_pts_test_with_img_value  = self.Verified_pts_test.select(self.Input_band + [self.classProperty])\n",
    "\n",
    "            self.classifier = ee.Classifier.smileRandomForest(numberOfTrees = self.Tree_num)\\\n",
    "                                       .train(features        = self.Verified_pts_train_with_img_value,\n",
    "                                              inputProperties = self.Input_band,\n",
    "                                              classProperty   = self.classProperty)\n",
    "            \n",
    "      \n",
    "    def Stp_1_Classification_on_img(self):\n",
    "\n",
    "        self.classification_img = self.Input_img.classify(self.classifier)\n",
    "   \n",
    "    \n",
    "    def Stp_2_Classification_on_Samples(self):\n",
    "        \n",
    "        # Classify the Train-data set.\n",
    "        self.Train_sample_classification   = self.Verified_pts_train_with_img_value.classify(self.classifier)\n",
    "        \n",
    "        # Classify the Test-data set.\n",
    "        self.Test_sample_classification    = self.Verified_pts_test_with_img_value.classify(self.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
